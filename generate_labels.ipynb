{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c669447",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N:\\PROJ_TPE\\TPE_20250525A01_e-5rps_conti_strain1\\Ic_100.png\n",
      "✅ Dataset generation complete.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "\n",
    "# ====== USER CONFIGURATION ======\n",
    "input_image_dir = r\"N:\\PROJ_TPE\\TPE_20250525A01_e-5rps_conti_strain1\"\n",
    "input_label_dir = r\"O:\\LJJ202107\\TPE_track_files\\TPE_20250525A01_e-5rps_e-2fps_N=528_linked_500frames_20250527a_refined.pkl\"  # folder with pkl files\n",
    "output_base_dir = r\"O:\\LJJ202107\\LJJ Jupyter Notebook Collection\\Mask_RCNN\\particle_track_cnn/dataset/train/\"\n",
    "image_ext = \".png\"  # or \".jpg\"\n",
    "# =================================\n",
    "\n",
    "os.makedirs(f\"{output_base_dir}/images\", exist_ok=True)\n",
    "os.makedirs(f\"{output_base_dir}/masks\", exist_ok=True)\n",
    "\n",
    "image_paths = sorted(glob(os.path.join(input_image_dir, f\"*{image_ext}\")))\n",
    "image_paths = [path for path in image_paths if \"Ib\" not in os.path.basename(path)]\n",
    "def extract_index(path):\n",
    "    # Extract the base file name\n",
    "    filename = os.path.basename(path)\n",
    "    # Look for a pattern like \"Ic_<number>\" before the extension\n",
    "    match = re.search(r\"Ic_(\\d+)\", filename)\n",
    "    return int(match.group(1)) if match else 0\n",
    "# Sort the image_paths using the extracted index as key\n",
    "sorted_image_paths = sorted(image_paths, key=extract_index)\n",
    "\n",
    "F = pd.read_pickle(input_label_dir)\n",
    "\n",
    "for frame in [100]:\n",
    "    # Load image and coordinates\n",
    "    image_path = sorted_image_paths[frame-1] #first image path is I_1\n",
    "    print(image_path)\n",
    "    image = cv2.imread(image_path)[:,:,0]\n",
    "\n",
    "    # Save image copy to output\n",
    "    cv2.imwrite(os.path.join(output_base_dir, \"images\", f\"frame_{frame}{image_ext}\"), image)\n",
    "\n",
    "    df = F[F.frame==frame]\n",
    "    # Create and save a mask for each disk\n",
    "    for i, row in df.iterrows():\n",
    "        x, y = int(row['x']), int(row['y'])\n",
    "        ptype = (row['r_px']>45)*1\n",
    "        mask = np.zeros(image.shape[:2], dtype=np.uint8)\n",
    "        cv2.circle(mask, (x, y), int(row['r_px']), 255, -1)  # filled circle\n",
    "        mask_filename = f\"frame_{frame}_object_{int(row['particle'])}_type_{ptype}.png\"\n",
    "        cv2.imwrite(os.path.join(output_base_dir, \"masks\", mask_filename), mask)\n",
    "\n",
    "print(\"✅ Dataset generation complete.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
